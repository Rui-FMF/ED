{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d04e613f",
   "metadata": {},
   "source": [
    "# Turbo Engine Failure Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07906c9f",
   "metadata": {},
   "source": [
    "#### Load Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c3efa4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "train_data = pd.read_csv(\"train_FD001.csv\", sep=\";\")\n",
    "test_data = pd.read_csv(\"test_FD001_100ex.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3431e11a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3100 17531 0.15025931850128446\n"
     ]
    }
   ],
   "source": [
    "lenYes = len([1 for v in train_data[\"Failure_status\"] if v==\"yes\"])\n",
    "lenNo = len([1 for v in train_data[\"Failure_status\"] if v==\"no\"])\n",
    "print(lenYes, lenNo, lenYes/(lenYes+lenNo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef030496",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebb3645",
   "metadata": {},
   "source": [
    "### Encode class labels\n",
    "Encoding is straightforward, as it is a binary classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36073c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\"yes\": 1,\n",
    "                 \"no\": 0}\n",
    "\n",
    "train_data[\"Failure_status\"] = train_data[\"Failure_status\"].map(label_mapping)\n",
    "test_data[\"Failure_status\"] = test_data[\"Failure_status\"].map(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149f7bf9",
   "metadata": {},
   "source": [
    "### Separate labels and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "69f1df0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data.iloc[:, :-1]\n",
    "y = train_data.iloc[:, -1]\n",
    "\n",
    "x_test = test_data.iloc[:, :-1]\n",
    "y_test = test_data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aa04c0",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "Since the profile of many of the features seems to approach a standard distribution, the group opted for a z-score normalization, which is not only appropriate for this dataset, it also has the added benefit of centering the data, which is import for some of the classifiers that will be used such as SVM and neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "217a7714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdScaler = StandardScaler()\n",
    "\n",
    "x = stdScaler.fit_transform(x)\n",
    "x_test = stdScaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c7d5d7",
   "metadata": {},
   "source": [
    "### Dimension Reduction\n",
    "The chosen approach for dimension reduction was a PCA. The basis for this decision is that not only is it benefitial for some classifiers, it is also useful for denoising, as we already know that the dataset has added noise and the contribution of noise to the total variance of the features is likely to be less significant than the patterns that will allow us to predict the label for each feature. Additionally, one of the main disadvantages of using a PCA for dimension reduction is that it becomes hard to understand what each resulting feature represents, however that is not a problem for our particular dataset, as the starting features are already anonymous, so there is little downside to this approach.\n",
    "\n",
    "Since the features are anonymous, it is also not possible for us to know beforehand the ideal explained variance to be considered for this problem, so it is chosen based on the performance obtained by the classifiers, readjusting as needed for each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "742f0863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9134299234365061 9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=0.9, svd_solver='full') # set PCA to explain 90% of the variance\n",
    "x = pca.fit_transform(x)\n",
    "x_test = pca.transform(x_test)\n",
    "print(sum(pca.explained_variance_ratio_), x.shape[1]) # it takes 9 components to explain at least 90% of the variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3cefde",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da106f6",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b884345c",
   "metadata": {},
   "source": [
    "Another model we experimented with was the Neural Network, the Multi-Layer Perceptron from sklearn. There were a lot of parameters to experiment with for the parameter grid, for the solver, activation and learning rate, we picked some of the ussually recomended choices and set them against eachother. The same went for the numerical values of alpha and learning rate init, however after the first trial of the later, it was clear that 0.001 was doing far better than other choices. The forced parameter max_iter, serves to make sure all of the combinations include 1000 iterations of maximum instead of the default 200, for them to have enough to converge. Finally the hidden layers were experimented with 2 and 3 layers, of sizes based on the number of features and 50% more and less, the best results happened when it had 12 sized layers, and having 3 layers didn't seem to give it a clear advantage over 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87559936",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "MLPClassifier().get_params()\n",
    "\n",
    "parameter_grid = [\n",
    "    {\n",
    "        'solver': ['adam', 'sgd'],\n",
    "        'max_iter': [1000],\n",
    "        'hidden_layer_sizes': [(9,9), (12,12),(12,12,12)],\n",
    "        'activation': ['tanh', 'relu'],\n",
    "        'alpha': [0.0001, 0.05],\n",
    "        'learning_rate': ['constant', 'adaptive'],\n",
    "        'learning_rate_init': [0.001]\n",
    "    }\n",
    "]\n",
    "\n",
    "grid_search = GridSearchCV(MLPClassifier(), parameter_grid, cv=5, scoring=\"accuracy\", verbose=0)\n",
    "grid_search.fit(x, y)\n",
    "results = pd.DataFrame(grid_search.cv_results_)\n",
    "y_pred = grid_search.predict(x_test)\n",
    "\n",
    "print(\"\\nCrossvalidation statistics:\")\n",
    "results = results[[\"rank_test_score\", \"params\", \"mean_test_score\", \"std_test_score\"]].sort_values(\"rank_test_score\")\n",
    "results = results.drop('params', axis=1).join(pd.DataFrame(results.params.values.tolist()))\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_rows\", 1000)\n",
    "display(results.style.hide_index())\n",
    "\n",
    "print(\"Classifier performance for best parameters:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405da03a",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3957f455",
   "metadata": {},
   "source": [
    "In an effort to try different options, we briefly looked at ensemble classifiers as a curiosity. Taking the best parameters for each of our classifiers, we make 3 classifiers and build a voting classifiers from it. Then train and test it considering 5-fold cross validation. Unfortunally, because we only have 3 classifiers all with relativy large accuracies as they stand, the ensemble model doesn't bring improvements, in fact the Neural Network and the Random forest likely vote against the SVM's correct prediction on the occassions that bring the accuracy down. Regardless we can see trough the confusion matrix that only 1 false positive and 7 false negatives appear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4905dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "def get_confusion_matrix(clf, y_pred_test, y_test):\n",
    "    cm = confusion_matrix(y_test, y_pred_test, labels=clf.classes_)\n",
    "    return cm\n",
    "\n",
    "def display_cm(clf, cm):\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf.classes_)\n",
    "    disp.plot()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd56fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "nn_clf1 = MLPClassifier(activation='relu', alpha=0.05, hidden_layer_sizes=(12,12), learning_rate='adaptive', learning_rate_init=0.001, max_iter=1000, solver='adam')\n",
    "rf_clf = RandomForestClassifier(criterion='entropy', max_depth=5, max_features='log2', n_estimators=500, n_jobs=-1, random_state=0)\n",
    "svm_clf = svm.SVC(gamma=100, C=10)\n",
    "\n",
    "ensemble_clf = VotingClassifier(estimators=[('mlp1',nn_clf1), ('rf',rf_clf), ('svm',svm_clf)], voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80f9e4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1, Class dist.: [14024  2480], Acc: 0.962\n",
      "Fold: 2, Class dist.: [14025  2480], Acc: 0.958\n",
      "Fold: 3, Class dist.: [14025  2480], Acc: 0.962\n",
      "Fold: 4, Class dist.: [14025  2480], Acc: 0.963\n",
      "Fold: 5, Class dist.: [14025  2480], Acc: 0.960\n",
      "\n",
      "CV accuracy: 0.961 +/- 0.002\n",
      "\n",
      " Generalization on the test set  \n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95        75\n",
      "           1       0.95      0.72      0.82        25\n",
      "\n",
      "    accuracy                           0.92       100\n",
      "   macro avg       0.93      0.85      0.88       100\n",
      "weighted avg       0.92      0.92      0.92       100\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores=[];    \n",
    "kfold = StratifiedKFold(n_splits=5,  shuffle=True).split(x, y)\n",
    "\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    Xtrain=stdScaler.fit_transform(x[train])\n",
    "    Xtest=stdScaler.transform(x[test])    \n",
    "    ensemble_clf.fit(Xtrain, y[train])\n",
    "    score = ensemble_clf.score(Xtest, y[test])\n",
    "    scores.append(score)\n",
    "    print('Fold: %s, Class dist.: %s, Acc: %.3f' % (k+1, np.bincount(y[train]), score))\n",
    "   \n",
    "print('\\nCV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))\n",
    "\n",
    "##Model trained with all training data\n",
    "print('\\n Generalization on the test set  \\n \\n')\n",
    "\n",
    "Xtr=stdScaler.fit_transform(x)\n",
    "Xtest=stdScaler.transform(x_test)    \n",
    "ensemble_clf.fit(Xtr, y)\n",
    "y_pred=ensemble_clf.predict(Xtest)\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n",
    "cm = get_confusion_matrix(ensemble_clf, y_pred, y_test)\n",
    "display_cm(ensemble_clf, cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffd598f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
